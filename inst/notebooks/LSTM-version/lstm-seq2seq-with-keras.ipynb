{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["['cat.txt', '_about.txt']\n"]}],"source":["import os, sys, time, random\n","import h5py\n","import numpy as np\n","print(os.listdir(\"./data/cat-eng\"))"]},{"cell_type":"code","execution_count":2,"metadata":{"_uuid":"31ae4ebe3257108c42bdf450073b8d54936a1cd6","trusted":true},"outputs":[],"source":["from keras.layers import *\n","from keras.models import *\n","from keras.utils import *\n","from keras.initializers import *\n","import tensorflow as tf"]},{"cell_type":"code","execution_count":3,"metadata":{"_uuid":"25a4e464236ee5b75cfa6808d8f8ef1f5abc4a5c","trusted":true},"outputs":[],"source":["batch_size = 64  # Batch size for training.\n","epochs = 400  # Number of epochs to train for.\n","latent_dim = 256  # Latent dimensionality of the encoding space.\n","num_samples = 1000  # Number of samples to train on.\n","# Path to the data txt file on disk.\n","data_path = \"./data/cat-eng/cat.txt\""]},{"cell_type":"code","execution_count":4,"metadata":{"_uuid":"fa696e274d7302ffd7a7b74cc40ec8a0eac6e60d","trusted":true},"outputs":[],"source":["# Vectorize the data.\n","input_texts = []\n","target_texts = []\n","input_characters = set()\n","target_characters = set()\n","with open(data_path, 'r', encoding='utf-8') as f:\n","    lines = f.read().split('\\n')\n","for line in lines[: min(num_samples, len(lines) - 1)]:\n","    input_text, target_text, extra_text = line.split('\\t')\n","    # We use \"tab\" as the \"start sequence\" character\n","    # for the targets, and \"\\n\" as \"end sequence\" character.\n","    target_text = '\\t' + target_text + '\\n'\n","    input_texts.append(input_text)\n","    target_texts.append(target_text)\n","    for char in input_text:\n","        if char not in input_characters:\n","            input_characters.add(char)\n","    for char in target_text:\n","        if char not in target_characters:\n","            target_characters.add(char)\n","\n","input_characters = sorted(list(input_characters))\n","target_characters = sorted(list(target_characters))\n","num_encoder_tokens = len(input_characters)\n","num_decoder_tokens = len(target_characters)\n","max_encoder_seq_length = max([len(txt) for txt in input_texts])\n","max_decoder_seq_length = max([len(txt) for txt in target_texts])"]},{"cell_type":"code","execution_count":5,"metadata":{"_uuid":"8a616775660a99cbd15478d757edd0f1e918ff23","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of samples: 1000\n","Number of unique input tokens: 66\n","Number of unique output tokens: 79\n","Max sequence length for inputs: 39\n","Max sequence length for outputs: 62\n"]}],"source":["print('Number of samples:', len(input_texts))\n","print('Number of unique input tokens:', num_encoder_tokens)\n","print('Number of unique output tokens:', num_decoder_tokens)\n","print('Max sequence length for inputs:', max_encoder_seq_length)\n","print('Max sequence length for outputs:', max_decoder_seq_length)"]},{"cell_type":"code","execution_count":6,"metadata":{"_uuid":"5392311afe30b92f780c230ac5e681d6076bca02","trusted":true},"outputs":[],"source":["input_token_index = dict(\n","    [(char, i) for i, char in enumerate(input_characters)])\n","target_token_index = dict(\n","    [(char, i) for i, char in enumerate(target_characters)])\n","\n","encoder_input_data = np.zeros(\n","    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n","    dtype='float32')\n","decoder_input_data = np.zeros(\n","    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n","    dtype='float32')\n","decoder_target_data = np.zeros(\n","    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n","    dtype='float32')\n","\n","for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n","    for t, char in enumerate(input_text):\n","        encoder_input_data[i, t, input_token_index[char]] = 1.\n","    for t, char in enumerate(target_text):\n","        # decoder_target_data is ahead of decoder_input_data by one timestep\n","        decoder_input_data[i, t, target_token_index[char]] = 1.\n","        if t > 0:\n","            # decoder_target_data will be ahead by one timestep\n","            # and will not include the start character.\n","            decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n"]},{"cell_type":"code","execution_count":7,"metadata":{"_uuid":"ecb42239d4b87c222b7513a2ff36fa1651666189","trusted":true},"outputs":[],"source":["# Define an input sequence and process it.\n","encoder_inputs = Input(shape=(None, num_encoder_tokens))\n","encoder = LSTM(latent_dim, return_state=True)\n","encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n","# We discard `encoder_outputs` and only keep the states.\n","encoder_states = [state_h, state_c]\n","\n","# Set up the decoder, using `encoder_states` as initial state.\n","decoder_inputs = Input(shape=(None, num_decoder_tokens))\n","# We set up our decoder to return full output sequences,\n","# and to return internal states as well. We don't use the\n","# return states in the training model, but we will use them in inference.\n","decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n","decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n","                                     initial_state=encoder_states)\n","decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n","decoder_outputs = decoder_dense(decoder_outputs)\n","# Define the model that will turn\n","# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n","model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"]},{"cell_type":"code","execution_count":8,"metadata":{"_uuid":"c220e0f83c25b61bcdfcb067eeaa5146d40e956b","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_1 (InputLayer)           [(None, None, 66)]   0           []                               \n","                                                                                                  \n"," input_2 (InputLayer)           [(None, None, 79)]   0           []                               \n","                                                                                                  \n"," lstm (LSTM)                    [(None, 256),        330752      ['input_1[0][0]']                \n","                                 (None, 256),                                                     \n","                                 (None, 256)]                                                     \n","                                                                                                  \n"," lstm_1 (LSTM)                  [(None, None, 256),  344064      ['input_2[0][0]',                \n","                                 (None, 256),                     'lstm[0][1]',                   \n","                                 (None, 256)]                     'lstm[0][2]']                   \n","                                                                                                  \n"," dense (Dense)                  (None, None, 79)     20303       ['lstm_1[0][0]']                 \n","                                                                                                  \n","==================================================================================================\n","Total params: 695,119\n","Trainable params: 695,119\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","[<KerasTensor: shape=(None, 256) dtype=float32 (created by layer 'lstm')>, <KerasTensor: shape=(None, 256) dtype=float32 (created by layer 'lstm')>, <KerasTensor: shape=(None, 256) dtype=float32 (created by layer 'lstm')>]\n"]}],"source":["model.summary()\n","# print(model.layers[-1].input)\n","print(model.layers[-3].output)"]},{"cell_type":"code","execution_count":9,"metadata":{"_uuid":"9f2c734844e2ba10ba58179226438888c0449d2d","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["encoder_input_data shape: (1000, 39, 66)\n","decoder_input_data shape: (1000, 62, 79)\n","decoder_target_data shape: (1000, 62, 79)\n"]}],"source":["print(\"encoder_input_data shape:\",encoder_input_data.shape)\n","print(\"decoder_input_data shape:\",decoder_input_data.shape)\n","print(\"decoder_target_data shape:\",decoder_target_data.shape)"]},{"cell_type":"code","execution_count":10,"metadata":{"_uuid":"4fb27c5a375ac72ecbc648404d849b9ddd56dfc0","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"]}],"source":["plot_model(model,show_shapes=True)"]},{"cell_type":"code","execution_count":11,"metadata":{"_uuid":"bcd0a4bd8b4cd2431539c7c507154f5eed78422f","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/400\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\humbe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(Adam, self).__init__(name, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 4s 77ms/step - loss: 1.4920 - val_loss: 1.9946\n","Epoch 2/400\n","13/13 [==============================] - 0s 22ms/step - loss: 1.3135 - val_loss: 1.9689\n","Epoch 3/400\n","13/13 [==============================] - 0s 22ms/step - loss: 1.2890 - val_loss: 1.9550\n","Epoch 4/400\n","13/13 [==============================] - 0s 22ms/step - loss: 1.2770 - val_loss: 1.9424\n","Epoch 5/400\n","13/13 [==============================] - 0s 22ms/step - loss: 1.2670 - val_loss: 1.9325\n","Epoch 6/400\n","13/13 [==============================] - 0s 22ms/step - loss: 1.2609 - val_loss: 1.9153\n","Epoch 7/400\n","13/13 [==============================] - 0s 22ms/step - loss: 1.2520 - val_loss: 1.9268\n","Epoch 8/400\n","13/13 [==============================] - 0s 22ms/step - loss: 1.2468 - val_loss: 1.8965\n","Epoch 9/400\n","13/13 [==============================] - 0s 23ms/step - loss: 1.2401 - val_loss: 1.8922\n","Epoch 10/400\n","13/13 [==============================] - 0s 22ms/step - loss: 1.2366 - val_loss: 1.8698\n","Epoch 11/400\n","13/13 [==============================] - 0s 22ms/step - loss: 1.2368 - val_loss: 1.8874\n","Epoch 12/400\n","13/13 [==============================] - 0s 21ms/step - loss: 1.2270 - val_loss: 1.8692\n","Epoch 13/400\n","13/13 [==============================] - 0s 22ms/step - loss: 1.2189 - val_loss: 1.8694\n","Epoch 14/400\n","13/13 [==============================] - 0s 22ms/step - loss: 1.2141 - val_loss: 1.8505\n","Epoch 15/400\n","13/13 [==============================] - 0s 22ms/step - loss: 1.2065 - val_loss: 1.8492\n","Epoch 16/400\n","13/13 [==============================] - 0s 21ms/step - loss: 1.1935 - val_loss: 1.8394\n","Epoch 17/400\n","13/13 [==============================] - 0s 22ms/step - loss: 1.2119 - val_loss: 1.8577\n","Epoch 18/400\n","13/13 [==============================] - 0s 22ms/step - loss: 1.2775 - val_loss: 1.9313\n","Epoch 19/400\n","13/13 [==============================] - 0s 22ms/step - loss: 1.2567 - val_loss: 1.9034\n","Epoch 20/400\n","13/13 [==============================] - 0s 22ms/step - loss: 1.2380 - val_loss: 1.8922\n","Epoch 21/400\n","13/13 [==============================] - 0s 21ms/step - loss: 1.2274 - val_loss: 1.8838\n","Epoch 22/400\n","13/13 [==============================] - 0s 22ms/step - loss: 1.2188 - val_loss: 1.8659\n","Epoch 23/400\n","13/13 [==============================] - 0s 22ms/step - loss: 1.2114 - val_loss: 1.8596\n","Epoch 24/400\n","13/13 [==============================] - 0s 23ms/step - loss: 1.2068 - val_loss: 1.8496\n","Epoch 25/400\n","13/13 [==============================] - 0s 21ms/step - loss: 1.2020 - val_loss: 1.8522\n","Epoch 26/400\n","13/13 [==============================] - 0s 22ms/step - loss: 1.1994 - val_loss: 1.8389\n","Epoch 27/400\n","13/13 [==============================] - 0s 22ms/step - loss: 1.1929 - val_loss: 1.8408\n","Epoch 28/400\n","13/13 [==============================] - 0s 21ms/step - loss: 1.1856 - val_loss: 1.8272\n","Epoch 29/400\n","13/13 [==============================] - 0s 22ms/step - loss: 1.1798 - val_loss: 1.8205\n","Epoch 30/400\n","13/13 [==============================] - 0s 22ms/step - loss: 1.1752 - val_loss: 1.8118\n","Epoch 31/400\n","13/13 [==============================] - 0s 22ms/step - loss: 1.1704 - val_loss: 1.8202\n","Epoch 32/400\n","13/13 [==============================] - 0s 22ms/step - loss: 1.1695 - val_loss: 1.8291\n","Epoch 33/400\n","13/13 [==============================] - 0s 22ms/step - loss: 1.1658 - val_loss: 1.8179\n","Epoch 34/400\n","13/13 [==============================] - 0s 22ms/step - loss: 1.1561 - val_loss: 1.8076\n","Epoch 35/400\n","13/13 [==============================] - 0s 22ms/step - loss: 1.1515 - val_loss: 1.8092\n","Epoch 36/400\n","13/13 [==============================] - 0s 22ms/step - loss: 1.1445 - val_loss: 1.7905\n","Epoch 37/400\n","13/13 [==============================] - 0s 22ms/step - loss: 1.1309 - val_loss: 1.7912\n","Epoch 38/400\n","13/13 [==============================] - 0s 22ms/step - loss: 1.1345 - val_loss: 1.7842\n","Epoch 39/400\n","13/13 [==============================] - 0s 22ms/step - loss: 1.1185 - val_loss: 1.7545\n","Epoch 40/400\n","13/13 [==============================] - 0s 22ms/step - loss: 1.1196 - val_loss: 1.7784\n","Epoch 41/400\n","13/13 [==============================] - 0s 22ms/step - loss: 1.1246 - val_loss: 1.8018\n","Epoch 42/400\n","13/13 [==============================] - 0s 22ms/step - loss: 1.1294 - val_loss: 1.7811\n","Epoch 43/400\n","13/13 [==============================] - 0s 22ms/step - loss: 1.1646 - val_loss: 1.8031\n","Epoch 44/400\n","13/13 [==============================] - 0s 22ms/step - loss: 1.1388 - val_loss: 1.7768\n","Epoch 45/400\n","13/13 [==============================] - 0s 22ms/step - loss: 1.1119 - val_loss: 1.7346\n","Epoch 46/400\n","13/13 [==============================] - 0s 22ms/step - loss: 1.0856 - val_loss: 1.6950\n","Epoch 47/400\n","13/13 [==============================] - 0s 22ms/step - loss: 1.0687 - val_loss: 1.6680\n","Epoch 48/400\n","13/13 [==============================] - 0s 22ms/step - loss: 1.0609 - val_loss: 1.6827\n","Epoch 49/400\n","13/13 [==============================] - 0s 22ms/step - loss: 1.0650 - val_loss: 1.6670\n","Epoch 50/400\n","13/13 [==============================] - 0s 22ms/step - loss: 1.0515 - val_loss: 1.6336\n","Epoch 51/400\n","13/13 [==============================] - 0s 22ms/step - loss: 1.0592 - val_loss: 1.6704\n","Epoch 52/400\n","13/13 [==============================] - 0s 22ms/step - loss: 1.0573 - val_loss: 1.6531\n","Epoch 53/400\n","13/13 [==============================] - 0s 22ms/step - loss: 1.0562 - val_loss: 1.6585\n","Epoch 54/400\n","13/13 [==============================] - 0s 22ms/step - loss: 1.0361 - val_loss: 1.6310\n","Epoch 55/400\n","13/13 [==============================] - 0s 22ms/step - loss: 1.0311 - val_loss: 1.6071\n","Epoch 56/400\n","13/13 [==============================] - 0s 22ms/step - loss: 1.0299 - val_loss: 1.5992\n","Epoch 57/400\n","13/13 [==============================] - 0s 22ms/step - loss: 1.0185 - val_loss: 1.6317\n","Epoch 58/400\n","13/13 [==============================] - 0s 23ms/step - loss: 1.0176 - val_loss: 1.6029\n","Epoch 59/400\n","13/13 [==============================] - 0s 22ms/step - loss: 1.0040 - val_loss: 1.5923\n","Epoch 60/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.9949 - val_loss: 1.5971\n","Epoch 61/400\n","13/13 [==============================] - 0s 25ms/step - loss: 0.9906 - val_loss: 1.5811\n","Epoch 62/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.9806 - val_loss: 1.5695\n","Epoch 63/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.9738 - val_loss: 1.5630\n","Epoch 64/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.9682 - val_loss: 1.5547\n","Epoch 65/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.9577 - val_loss: 1.5588\n","Epoch 66/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.9549 - val_loss: 1.5439\n","Epoch 67/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.9507 - val_loss: 1.6070\n","Epoch 68/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.9863 - val_loss: 1.5686\n","Epoch 69/400\n","13/13 [==============================] - 0s 25ms/step - loss: 0.9614 - val_loss: 1.5409\n","Epoch 70/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.9515 - val_loss: 1.5419\n","Epoch 71/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.9366 - val_loss: 1.5230\n","Epoch 72/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.9261 - val_loss: 1.5289\n","Epoch 73/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.9263 - val_loss: 1.5231\n","Epoch 74/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.9206 - val_loss: 1.5150\n","Epoch 75/400\n","13/13 [==============================] - 0s 23ms/step - loss: 0.9114 - val_loss: 1.5175\n","Epoch 76/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.9034 - val_loss: 1.4978\n","Epoch 77/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.9701 - val_loss: 1.6089\n","Epoch 78/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.9512 - val_loss: 1.5356\n","Epoch 79/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.9259 - val_loss: 1.5261\n","Epoch 80/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.9042 - val_loss: 1.5141\n","Epoch 81/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.8914 - val_loss: 1.5009\n","Epoch 82/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.8843 - val_loss: 1.5042\n","Epoch 83/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.8770 - val_loss: 1.4892\n","Epoch 84/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.8748 - val_loss: 1.5023\n","Epoch 85/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.8735 - val_loss: 1.4984\n","Epoch 86/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.8640 - val_loss: 1.4856\n","Epoch 87/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.8630 - val_loss: 1.4851\n","Epoch 88/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.8807 - val_loss: 1.5101\n","Epoch 89/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.8684 - val_loss: 1.4775\n","Epoch 90/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.8584 - val_loss: 1.5067\n","Epoch 91/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.8565 - val_loss: 1.4767\n","Epoch 92/400\n","13/13 [==============================] - 0s 23ms/step - loss: 0.8481 - val_loss: 1.4980\n","Epoch 93/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.8439 - val_loss: 1.4627\n","Epoch 94/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.8345 - val_loss: 1.4789\n","Epoch 95/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.8240 - val_loss: 1.4632\n","Epoch 96/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.8139 - val_loss: 1.4533\n","Epoch 97/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.8049 - val_loss: 1.4551\n","Epoch 98/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.8005 - val_loss: 1.4486\n","Epoch 99/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.7923 - val_loss: 1.4570\n","Epoch 100/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.7857 - val_loss: 1.4411\n","Epoch 101/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.7788 - val_loss: 1.4505\n","Epoch 102/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.7710 - val_loss: 1.4418\n","Epoch 103/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.7641 - val_loss: 1.4363\n","Epoch 104/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.7556 - val_loss: 1.4163\n","Epoch 105/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.7459 - val_loss: 1.4220\n","Epoch 106/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.7401 - val_loss: 1.4159\n","Epoch 107/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.7322 - val_loss: 1.4036\n","Epoch 108/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.7235 - val_loss: 1.4109\n","Epoch 109/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.7165 - val_loss: 1.3938\n","Epoch 110/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.7095 - val_loss: 1.3952\n","Epoch 111/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.7036 - val_loss: 1.4036\n","Epoch 112/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.6989 - val_loss: 1.4049\n","Epoch 113/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.6938 - val_loss: 1.3924\n","Epoch 114/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.6873 - val_loss: 1.3877\n","Epoch 115/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.6850 - val_loss: 1.3947\n","Epoch 116/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.6986 - val_loss: 1.4032\n","Epoch 117/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.6891 - val_loss: 1.3875\n","Epoch 118/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.6805 - val_loss: 1.3878\n","Epoch 119/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.6773 - val_loss: 1.3820\n","Epoch 120/400\n","13/13 [==============================] - 0s 24ms/step - loss: 0.6730 - val_loss: 1.3800\n","Epoch 121/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.6661 - val_loss: 1.3750\n","Epoch 122/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.6551 - val_loss: 1.3840\n","Epoch 123/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.6494 - val_loss: 1.3828\n","Epoch 124/400\n","13/13 [==============================] - 0s 23ms/step - loss: 0.6455 - val_loss: 1.3828\n","Epoch 125/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.6405 - val_loss: 1.3767\n","Epoch 126/400\n","13/13 [==============================] - 0s 23ms/step - loss: 0.6351 - val_loss: 1.3810\n","Epoch 127/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.6313 - val_loss: 1.3989\n","Epoch 128/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.6292 - val_loss: 1.3819\n","Epoch 129/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.6241 - val_loss: 1.3821\n","Epoch 130/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.6210 - val_loss: 1.3814\n","Epoch 131/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.6152 - val_loss: 1.3906\n","Epoch 132/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.6180 - val_loss: 1.3885\n","Epoch 133/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.6514 - val_loss: 1.3896\n","Epoch 134/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.6395 - val_loss: 1.3822\n","Epoch 135/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.6188 - val_loss: 1.3846\n","Epoch 136/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.6106 - val_loss: 1.3936\n","Epoch 137/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.6039 - val_loss: 1.3826\n","Epoch 138/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.5952 - val_loss: 1.3925\n","Epoch 139/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.5922 - val_loss: 1.3944\n","Epoch 140/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.5877 - val_loss: 1.3886\n","Epoch 141/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.5838 - val_loss: 1.3958\n","Epoch 142/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.5771 - val_loss: 1.3983\n","Epoch 143/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.5788 - val_loss: 1.3995\n","Epoch 144/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.5730 - val_loss: 1.4013\n","Epoch 145/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.5684 - val_loss: 1.4079\n","Epoch 146/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.5665 - val_loss: 1.4084\n","Epoch 147/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.5649 - val_loss: 1.4095\n","Epoch 148/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.5629 - val_loss: 1.4023\n","Epoch 149/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.5592 - val_loss: 1.4140\n","Epoch 150/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.5552 - val_loss: 1.4191\n","Epoch 151/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.5491 - val_loss: 1.4167\n","Epoch 152/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.5432 - val_loss: 1.4156\n","Epoch 153/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.5418 - val_loss: 1.4150\n","Epoch 154/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.5390 - val_loss: 1.4282\n","Epoch 155/400\n","13/13 [==============================] - 0s 23ms/step - loss: 0.5379 - val_loss: 1.4212\n","Epoch 156/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.5366 - val_loss: 1.4198\n","Epoch 157/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.5297 - val_loss: 1.4184\n","Epoch 158/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.5277 - val_loss: 1.4205\n","Epoch 159/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.5242 - val_loss: 1.4313\n","Epoch 160/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.5211 - val_loss: 1.4249\n","Epoch 161/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.5194 - val_loss: 1.4338\n","Epoch 162/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.5188 - val_loss: 1.4455\n","Epoch 163/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.5136 - val_loss: 1.4433\n","Epoch 164/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.5099 - val_loss: 1.4510\n","Epoch 165/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.5089 - val_loss: 1.4440\n","Epoch 166/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.5089 - val_loss: 1.4489\n","Epoch 167/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.5016 - val_loss: 1.4603\n","Epoch 168/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.4969 - val_loss: 1.4497\n","Epoch 169/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.4945 - val_loss: 1.4577\n","Epoch 170/400\n","13/13 [==============================] - 0s 23ms/step - loss: 0.4972 - val_loss: 1.4547\n","Epoch 171/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.4948 - val_loss: 1.4619\n","Epoch 172/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.4884 - val_loss: 1.4609\n","Epoch 173/400\n","13/13 [==============================] - 0s 23ms/step - loss: 0.4835 - val_loss: 1.4652\n","Epoch 174/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.4832 - val_loss: 1.4624\n","Epoch 175/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.4793 - val_loss: 1.4631\n","Epoch 176/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.4766 - val_loss: 1.4672\n","Epoch 177/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.4715 - val_loss: 1.4636\n","Epoch 178/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.4716 - val_loss: 1.4681\n","Epoch 179/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.4773 - val_loss: 1.4778\n","Epoch 180/400\n","13/13 [==============================] - 0s 21ms/step - loss: 0.4716 - val_loss: 1.4720\n","Epoch 181/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.4671 - val_loss: 1.4854\n","Epoch 182/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.4630 - val_loss: 1.4892\n","Epoch 183/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.4631 - val_loss: 1.4805\n","Epoch 184/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.4625 - val_loss: 1.4832\n","Epoch 185/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.4621 - val_loss: 1.4817\n","Epoch 186/400\n","13/13 [==============================] - 0s 23ms/step - loss: 0.4544 - val_loss: 1.4952\n","Epoch 187/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.4517 - val_loss: 1.4935\n","Epoch 188/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.4488 - val_loss: 1.4990\n","Epoch 189/400\n","13/13 [==============================] - 0s 23ms/step - loss: 0.4450 - val_loss: 1.5044\n","Epoch 190/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.4412 - val_loss: 1.4911\n","Epoch 191/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.4415 - val_loss: 1.5088\n","Epoch 192/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.4424 - val_loss: 1.5111\n","Epoch 193/400\n","13/13 [==============================] - 0s 23ms/step - loss: 0.4389 - val_loss: 1.5144\n","Epoch 194/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.4336 - val_loss: 1.5003\n","Epoch 195/400\n","13/13 [==============================] - 0s 24ms/step - loss: 0.4345 - val_loss: 1.5199\n","Epoch 196/400\n","13/13 [==============================] - 0s 23ms/step - loss: 0.4406 - val_loss: 1.5189\n","Epoch 197/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.4383 - val_loss: 1.5156\n","Epoch 198/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.4323 - val_loss: 1.5134\n","Epoch 199/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.4273 - val_loss: 1.5148\n","Epoch 200/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.4246 - val_loss: 1.5345\n","Epoch 201/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.4191 - val_loss: 1.5223\n","Epoch 202/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.4185 - val_loss: 1.5313\n","Epoch 203/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.4175 - val_loss: 1.5268\n","Epoch 204/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.4147 - val_loss: 1.5327\n","Epoch 205/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.4103 - val_loss: 1.5439\n","Epoch 206/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.4065 - val_loss: 1.5448\n","Epoch 207/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.4046 - val_loss: 1.5521\n","Epoch 208/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.4030 - val_loss: 1.5525\n","Epoch 209/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.4042 - val_loss: 1.5414\n","Epoch 210/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.4040 - val_loss: 1.5534\n","Epoch 211/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.4018 - val_loss: 1.5597\n","Epoch 212/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.4000 - val_loss: 1.5655\n","Epoch 213/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.3966 - val_loss: 1.5507\n","Epoch 214/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.3951 - val_loss: 1.5619\n","Epoch 215/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.3895 - val_loss: 1.5766\n","Epoch 216/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.3896 - val_loss: 1.5841\n","Epoch 217/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.3883 - val_loss: 1.5743\n","Epoch 218/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.3876 - val_loss: 1.5777\n","Epoch 219/400\n","13/13 [==============================] - 0s 23ms/step - loss: 0.3910 - val_loss: 1.5733\n","Epoch 220/400\n","13/13 [==============================] - 0s 23ms/step - loss: 0.3855 - val_loss: 1.5826\n","Epoch 221/400\n","13/13 [==============================] - 0s 23ms/step - loss: 0.3814 - val_loss: 1.5667\n","Epoch 222/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.3768 - val_loss: 1.5764\n","Epoch 223/400\n","13/13 [==============================] - 0s 23ms/step - loss: 0.3795 - val_loss: 1.5617\n","Epoch 224/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.3828 - val_loss: 1.5885\n","Epoch 225/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.3817 - val_loss: 1.5810\n","Epoch 226/400\n","13/13 [==============================] - 0s 23ms/step - loss: 0.3790 - val_loss: 1.5849\n","Epoch 227/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.3740 - val_loss: 1.5948\n","Epoch 228/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.3712 - val_loss: 1.5927\n","Epoch 229/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.3686 - val_loss: 1.5967\n","Epoch 230/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.3637 - val_loss: 1.5981\n","Epoch 231/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.3612 - val_loss: 1.6071\n","Epoch 232/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.3593 - val_loss: 1.6053\n","Epoch 233/400\n","13/13 [==============================] - 0s 23ms/step - loss: 0.3553 - val_loss: 1.6096\n","Epoch 234/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.3535 - val_loss: 1.6157\n","Epoch 235/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.3579 - val_loss: 1.6233\n","Epoch 236/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.3569 - val_loss: 1.6226\n","Epoch 237/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.3585 - val_loss: 1.6126\n","Epoch 238/400\n","13/13 [==============================] - 0s 23ms/step - loss: 0.3563 - val_loss: 1.6262\n","Epoch 239/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.3530 - val_loss: 1.6194\n","Epoch 240/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.3516 - val_loss: 1.6078\n","Epoch 241/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.3480 - val_loss: 1.6315\n","Epoch 242/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.3478 - val_loss: 1.6287\n","Epoch 243/400\n","13/13 [==============================] - 0s 23ms/step - loss: 0.3495 - val_loss: 1.6370\n","Epoch 244/400\n","13/13 [==============================] - 0s 23ms/step - loss: 0.3595 - val_loss: 1.6392\n","Epoch 245/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.3649 - val_loss: 1.6371\n","Epoch 246/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.3611 - val_loss: 1.6443\n","Epoch 247/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.3574 - val_loss: 1.6347\n","Epoch 248/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.3528 - val_loss: 1.6482\n","Epoch 249/400\n","13/13 [==============================] - 0s 23ms/step - loss: 0.3506 - val_loss: 1.6473\n","Epoch 250/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.3481 - val_loss: 1.6636\n","Epoch 251/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.3468 - val_loss: 1.6496\n","Epoch 252/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.3415 - val_loss: 1.6532\n","Epoch 253/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.3372 - val_loss: 1.6480\n","Epoch 254/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.3334 - val_loss: 1.6573\n","Epoch 255/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.3304 - val_loss: 1.6554\n","Epoch 256/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.3305 - val_loss: 1.6626\n","Epoch 257/400\n","13/13 [==============================] - 0s 24ms/step - loss: 0.3290 - val_loss: 1.6574\n","Epoch 258/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.3270 - val_loss: 1.6664\n","Epoch 259/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.3251 - val_loss: 1.6577\n","Epoch 260/400\n","13/13 [==============================] - 0s 23ms/step - loss: 0.3291 - val_loss: 1.6609\n","Epoch 261/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.3284 - val_loss: 1.6655\n","Epoch 262/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.3245 - val_loss: 1.6740\n","Epoch 263/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.3207 - val_loss: 1.6665\n","Epoch 264/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.3183 - val_loss: 1.6812\n","Epoch 265/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.3148 - val_loss: 1.6765\n","Epoch 266/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.3140 - val_loss: 1.6807\n","Epoch 267/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.3124 - val_loss: 1.6808\n","Epoch 268/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.3114 - val_loss: 1.6859\n","Epoch 269/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.3100 - val_loss: 1.6932\n","Epoch 270/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.3107 - val_loss: 1.6862\n","Epoch 271/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.3112 - val_loss: 1.6977\n","Epoch 272/400\n","13/13 [==============================] - 0s 24ms/step - loss: 0.3134 - val_loss: 1.6941\n","Epoch 273/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.3122 - val_loss: 1.6834\n","Epoch 274/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.3143 - val_loss: 1.7012\n","Epoch 275/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.3132 - val_loss: 1.6911\n","Epoch 276/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.3133 - val_loss: 1.7062\n","Epoch 277/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.3079 - val_loss: 1.7031\n","Epoch 278/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.3027 - val_loss: 1.6957\n","Epoch 279/400\n","13/13 [==============================] - 0s 23ms/step - loss: 0.3012 - val_loss: 1.7108\n","Epoch 280/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.3013 - val_loss: 1.7183\n","Epoch 281/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.3004 - val_loss: 1.7053\n","Epoch 282/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2972 - val_loss: 1.7094\n","Epoch 283/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2982 - val_loss: 1.7078\n","Epoch 284/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2980 - val_loss: 1.7251\n","Epoch 285/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.3003 - val_loss: 1.7121\n","Epoch 286/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2982 - val_loss: 1.7087\n","Epoch 287/400\n","13/13 [==============================] - 0s 24ms/step - loss: 0.2960 - val_loss: 1.6983\n","Epoch 288/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2942 - val_loss: 1.7086\n","Epoch 289/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2940 - val_loss: 1.7244\n","Epoch 290/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2960 - val_loss: 1.7196\n","Epoch 291/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2908 - val_loss: 1.7259\n","Epoch 292/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2866 - val_loss: 1.7318\n","Epoch 293/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2847 - val_loss: 1.7246\n","Epoch 294/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2826 - val_loss: 1.7351\n","Epoch 295/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2789 - val_loss: 1.7324\n","Epoch 296/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2772 - val_loss: 1.7449\n","Epoch 297/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2779 - val_loss: 1.7409\n","Epoch 298/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2759 - val_loss: 1.7459\n","Epoch 299/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2748 - val_loss: 1.7408\n","Epoch 300/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2738 - val_loss: 1.7384\n","Epoch 301/400\n","13/13 [==============================] - 0s 24ms/step - loss: 0.2726 - val_loss: 1.7370\n","Epoch 302/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2724 - val_loss: 1.7377\n","Epoch 303/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2755 - val_loss: 1.7530\n","Epoch 304/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2789 - val_loss: 1.7532\n","Epoch 305/400\n","13/13 [==============================] - 0s 23ms/step - loss: 0.2801 - val_loss: 1.7513\n","Epoch 306/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2789 - val_loss: 1.7480\n","Epoch 307/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2797 - val_loss: 1.7580\n","Epoch 308/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2939 - val_loss: 1.7416\n","Epoch 309/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2984 - val_loss: 1.7558\n","Epoch 310/400\n","13/13 [==============================] - 0s 23ms/step - loss: 0.2936 - val_loss: 1.7547\n","Epoch 311/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2887 - val_loss: 1.7539\n","Epoch 312/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2841 - val_loss: 1.7585\n","Epoch 313/400\n","13/13 [==============================] - 0s 23ms/step - loss: 0.2797 - val_loss: 1.7694\n","Epoch 314/400\n","13/13 [==============================] - 0s 24ms/step - loss: 0.2759 - val_loss: 1.7647\n","Epoch 315/400\n","13/13 [==============================] - 0s 21ms/step - loss: 0.2723 - val_loss: 1.7648\n","Epoch 316/400\n","13/13 [==============================] - 0s 23ms/step - loss: 0.2691 - val_loss: 1.7623\n","Epoch 317/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2672 - val_loss: 1.7723\n","Epoch 318/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2666 - val_loss: 1.7609\n","Epoch 319/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2651 - val_loss: 1.7841\n","Epoch 320/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2664 - val_loss: 1.7698\n","Epoch 321/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2663 - val_loss: 1.7821\n","Epoch 322/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2664 - val_loss: 1.7824\n","Epoch 323/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2637 - val_loss: 1.7815\n","Epoch 324/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2595 - val_loss: 1.7774\n","Epoch 325/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2573 - val_loss: 1.7857\n","Epoch 326/400\n","13/13 [==============================] - 0s 23ms/step - loss: 0.2559 - val_loss: 1.7800\n","Epoch 327/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2557 - val_loss: 1.7814\n","Epoch 328/400\n","13/13 [==============================] - 0s 24ms/step - loss: 0.2555 - val_loss: 1.7848\n","Epoch 329/400\n","13/13 [==============================] - 0s 23ms/step - loss: 0.2526 - val_loss: 1.7816\n","Epoch 330/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2517 - val_loss: 1.7941\n","Epoch 331/400\n","13/13 [==============================] - 0s 23ms/step - loss: 0.2519 - val_loss: 1.8049\n","Epoch 332/400\n","13/13 [==============================] - 0s 23ms/step - loss: 0.2510 - val_loss: 1.7990\n","Epoch 333/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2519 - val_loss: 1.8136\n","Epoch 334/400\n","13/13 [==============================] - 0s 24ms/step - loss: 0.2536 - val_loss: 1.8118\n","Epoch 335/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2552 - val_loss: 1.7886\n","Epoch 336/400\n","13/13 [==============================] - 0s 23ms/step - loss: 0.2565 - val_loss: 1.8016\n","Epoch 337/400\n","13/13 [==============================] - 0s 23ms/step - loss: 0.2556 - val_loss: 1.8118\n","Epoch 338/400\n","13/13 [==============================] - 0s 23ms/step - loss: 0.2524 - val_loss: 1.8031\n","Epoch 339/400\n","13/13 [==============================] - 0s 24ms/step - loss: 0.2511 - val_loss: 1.7978\n","Epoch 340/400\n","13/13 [==============================] - 0s 24ms/step - loss: 0.2506 - val_loss: 1.8097\n","Epoch 341/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2485 - val_loss: 1.8090\n","Epoch 342/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2456 - val_loss: 1.8195\n","Epoch 343/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2476 - val_loss: 1.8005\n","Epoch 344/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2480 - val_loss: 1.8225\n","Epoch 345/400\n","13/13 [==============================] - 0s 23ms/step - loss: 0.2496 - val_loss: 1.8210\n","Epoch 346/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2515 - val_loss: 1.8300\n","Epoch 347/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2569 - val_loss: 1.8149\n","Epoch 348/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2686 - val_loss: 1.8270\n","Epoch 349/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2663 - val_loss: 1.8214\n","Epoch 350/400\n","13/13 [==============================] - 0s 23ms/step - loss: 0.2659 - val_loss: 1.8069\n","Epoch 351/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2626 - val_loss: 1.8178\n","Epoch 352/400\n","13/13 [==============================] - 0s 24ms/step - loss: 0.2524 - val_loss: 1.8219\n","Epoch 353/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2456 - val_loss: 1.8283\n","Epoch 354/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2425 - val_loss: 1.8179\n","Epoch 355/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2383 - val_loss: 1.8179\n","Epoch 356/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2362 - val_loss: 1.8342\n","Epoch 357/400\n","13/13 [==============================] - 0s 23ms/step - loss: 0.2340 - val_loss: 1.8313\n","Epoch 358/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2322 - val_loss: 1.8370\n","Epoch 359/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2307 - val_loss: 1.8423\n","Epoch 360/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2288 - val_loss: 1.8320\n","Epoch 361/400\n","13/13 [==============================] - 0s 23ms/step - loss: 0.2284 - val_loss: 1.8500\n","Epoch 362/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2282 - val_loss: 1.8422\n","Epoch 363/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2279 - val_loss: 1.8439\n","Epoch 364/400\n","13/13 [==============================] - 0s 24ms/step - loss: 0.2265 - val_loss: 1.8538\n","Epoch 365/400\n","13/13 [==============================] - 0s 23ms/step - loss: 0.2259 - val_loss: 1.8508\n","Epoch 366/400\n","13/13 [==============================] - 0s 23ms/step - loss: 0.2265 - val_loss: 1.8634\n","Epoch 367/400\n","13/13 [==============================] - 0s 23ms/step - loss: 0.2268 - val_loss: 1.8474\n","Epoch 368/400\n","13/13 [==============================] - 0s 23ms/step - loss: 0.2263 - val_loss: 1.8675\n","Epoch 369/400\n","13/13 [==============================] - 0s 23ms/step - loss: 0.2276 - val_loss: 1.8540\n","Epoch 370/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2279 - val_loss: 1.8610\n","Epoch 371/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2258 - val_loss: 1.8768\n","Epoch 372/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2264 - val_loss: 1.8628\n","Epoch 373/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2242 - val_loss: 1.8643\n","Epoch 374/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2242 - val_loss: 1.8750\n","Epoch 375/400\n","13/13 [==============================] - 0s 25ms/step - loss: 0.2260 - val_loss: 1.8721\n","Epoch 376/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2270 - val_loss: 1.8795\n","Epoch 377/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2265 - val_loss: 1.8772\n","Epoch 378/400\n","13/13 [==============================] - 0s 23ms/step - loss: 0.2262 - val_loss: 1.8746\n","Epoch 379/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2246 - val_loss: 1.8694\n","Epoch 380/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2235 - val_loss: 1.8600\n","Epoch 381/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2219 - val_loss: 1.8659\n","Epoch 382/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2205 - val_loss: 1.8678\n","Epoch 383/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2223 - val_loss: 1.8822\n","Epoch 384/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2215 - val_loss: 1.8772\n","Epoch 385/400\n","13/13 [==============================] - 0s 21ms/step - loss: 0.2218 - val_loss: 1.8915\n","Epoch 386/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2208 - val_loss: 1.8743\n","Epoch 387/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2195 - val_loss: 1.8739\n","Epoch 388/400\n","13/13 [==============================] - 0s 24ms/step - loss: 0.2179 - val_loss: 1.8797\n","Epoch 389/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2160 - val_loss: 1.8839\n","Epoch 390/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2148 - val_loss: 1.8941\n","Epoch 391/400\n","13/13 [==============================] - 0s 23ms/step - loss: 0.2145 - val_loss: 1.8876\n","Epoch 392/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2127 - val_loss: 1.8898\n","Epoch 393/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2118 - val_loss: 1.9006\n","Epoch 394/400\n","13/13 [==============================] - 0s 23ms/step - loss: 0.2110 - val_loss: 1.9052\n","Epoch 395/400\n","13/13 [==============================] - 0s 23ms/step - loss: 0.2098 - val_loss: 1.8978\n","Epoch 396/400\n","13/13 [==============================] - 0s 23ms/step - loss: 0.2086 - val_loss: 1.9032\n","Epoch 397/400\n","13/13 [==============================] - 0s 23ms/step - loss: 0.2094 - val_loss: 1.8988\n","Epoch 398/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2107 - val_loss: 1.9018\n","Epoch 399/400\n","13/13 [==============================] - 0s 24ms/step - loss: 0.2102 - val_loss: 1.9036\n","Epoch 400/400\n","13/13 [==============================] - 0s 22ms/step - loss: 0.2105 - val_loss: 1.9080\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x25acdd544c0>"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["\n","# Run training\n","from keras.optimizers import * \n","model.compile(optimizer=Adam(lr=0.01, beta_1=0.9, beta_2=0.999, decay=0.001), loss='categorical_crossentropy')\n","model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n","          batch_size=batch_size,\n","          epochs=epochs, \n","          validation_split=0.2)"]},{"cell_type":"code","execution_count":12,"metadata":{"_uuid":"fd0f32d41296a9cccc9639092c591582448abebb","trusted":true},"outputs":[],"source":["# Define sampling models\n","encoder_model = Model(encoder_inputs, encoder_states)\n","decoder_state_input_h = Input(shape=(latent_dim,))\n","decoder_state_input_c = Input(shape=(latent_dim,))\n","decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n","decoder_outputs, state_h, state_c = decoder_lstm(\n","    decoder_inputs, initial_state=decoder_states_inputs)\n","decoder_states = [state_h, state_c]\n","decoder_outputs = decoder_dense(decoder_outputs)\n","decoder_model = Model(\n","    [decoder_inputs] + decoder_states_inputs,\n","    [decoder_outputs] + decoder_states)"]},{"cell_type":"code","execution_count":13,"metadata":{"_uuid":"56264615ed9b13fe15c0c4ea0d53a138625b0253","trusted":true},"outputs":[],"source":["# Reverse-lookup token index to decode sequences back to\n","# something readable.\n","reverse_input_char_index = dict(\n","    (i, char) for char, i in input_token_index.items())\n","reverse_target_char_index = dict(\n","    (i, char) for char, i in target_token_index.items())\n","\n","\n","def decode_sequence(input_seq):\n","    # Encode the input as state vectors.\n","    states_value = encoder_model.predict(input_seq)\n","\n","    # Generate empty target sequence of length 1.\n","    target_seq = np.zeros((1, 1, num_decoder_tokens))\n","    # Populate the first character of target sequence with the start character.\n","    target_seq[0, 0, target_token_index['\\t']] = 1.\n","\n","    # Sampling loop for a batch of sequences\n","    # (to simplify, here we assume a batch of size 1).\n","    stop_condition = False\n","    decoded_sentence = ''\n","    while not stop_condition:\n","        output_tokens, h, c = decoder_model.predict(\n","            [target_seq] + states_value)\n","\n","        # Sample a token\n","        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n","        sampled_char = reverse_target_char_index[sampled_token_index]\n","        decoded_sentence += sampled_char\n","\n","        # Exit condition: either hit max length\n","        # or find stop character.\n","        if (sampled_char == '\\n' or\n","           len(decoded_sentence) > max_decoder_seq_length):\n","            stop_condition = True\n","\n","        # Update the target sequence (of length 1).\n","        target_seq = np.zeros((1, 1, num_decoder_tokens))\n","        target_seq[0, 0, sampled_token_index] = 1.\n","\n","        # Update states\n","        states_value = [h, c]\n","\n","    return decoded_sentence"]},{"cell_type":"code","execution_count":14,"metadata":{"_uuid":"be16fcb708fb9a89ae7b4f447de86ec0a7654db6","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 304ms/step\n","1/1 [==============================] - 0s 301ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 17ms/step\n","-\n","Input sentence: Wow!\n","Decoded sentence: Carai.\n","\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","-\n","Input sentence: Wait.\n","Decoded sentence: Espera't.\n","\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","-\n","Input sentence: I left.\n","Decoded sentence: M'en vaig anar.\n","\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 15ms/step\n","-\n","Input sentence: Really?\n","Decoded sentence: De veritat.\n","\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 17ms/step\n","-\n","Input sentence: Thanks!\n","Decoded sentence: Grcies.\n","\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 17ms/step\n","-\n","Input sentence: Thanks.\n","Decoded sentence: Grcies.\n","\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","-\n","Input sentence: Get out!\n","Decoded sentence: Fora.\n","\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","-\n","Input sentence: Goodbye!\n","Decoded sentence: Adu.\n","\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","-\n","Input sentence: I agree.\n","Decoded sentence: Hi estic d'acor.\n","\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 18ms/step\n","-\n","Input sentence: Hurry up.\n","Decoded sentence: Afanya't.\n","\n"]}],"source":["\n","for seq_index in range(10):\n","    # Take one sequence (part of the training set)\n","    # for trying out decoding.\n","    input_seq = encoder_input_data[seq_index: seq_index + 1]\n","    decoded_sentence = decode_sequence(input_seq)\n","    print('-')\n","    print('Input sentence:', input_texts[seq_index])\n","    print('Decoded sentence:', decoded_sentence)"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"499e7f2cde6d03cc871b0a1ec372498827f731a3","trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"b511cb4777fa0113377a87582d366541ea949a10","trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"5f19fc14dd5cc64ad0c81c33a354dbed43f7236a","trusted":true},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.6 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"vscode":{"interpreter":{"hash":"5264f721a23242131e2cd1435c6f396c4a07f3216f42f5a927698946e7ff8eef"}}},"nbformat":4,"nbformat_minor":1}
